{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f794efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Optional, List, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084df113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()  # take environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0c8e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23ece69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationSchema(BaseModel):\n",
    "    score: int = Field(description=\"Score between 1 and 10\")\n",
    "    feedback: str = Field(description=\"Detailed feedback on the essay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fbd5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model = model.with_structured_output(EvaluationSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9513b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_text = \"\"\"Technology has fundamentally transformed modern education, evolving from a supplementary tool to an essential core component of the learning environment. Its role is multifaceted, breaking down traditional barriers and creating dynamic, accessible, and personalized experiences for students.\n",
    "\n",
    "Classrooms are no longer confined to physical spaces. Digital platforms, interactive whiteboards, and educational software make lessons more engaging, catering to diverse learning styles. More importantly, the internet provides unprecedented access to a vast repository of global knowledge and resources, democratizing education for learners everywhere.\n",
    "\n",
    "Furthermore, technology enables personalized learning paths. Adaptive software can tailor lessons to a studentâ€™s individual pace and understanding, while data analytics help educators identify and address learning gaps promptly. From collaborative tools that connect students across the globe to immersive simulations that bring complex concepts to life, technology is not just changing how we teach, but enhancing how we learn, fostering a more inclusive and effective educational landscape for the 21st century.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c649a1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"Evaluate the following UPSC essay on the topic 'Role of technology in modern education'. Provide a score between 1 and 10 and detailed feedback.\\n\\nEssay:\\n{essay_text}\"\n",
    "structured_model.invoke(prompt).score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8762617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining state\n",
    "class UPSCState(TypedDict):\n",
    "    essay: str\n",
    "    language_feedback: Optional[str]\n",
    "    analysis_feedback: Optional[str]\n",
    "    clarity_feedback: Optional[str]\n",
    "    overall_feedback: Optional[str]\n",
    "    individual_scores: Annotated[List[int], operator.add]  # to accumulate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f426b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate language function\n",
    "def evaluate_language(state: UPSCState):\n",
    "    \n",
    "    prompt = f\"Evaluate the language quality of the following essay. Provide a score between 1 and 10 and detailed feedback.\\n\\nEssay:\\n{state['essay']}\"\n",
    "    result = structured_model.invoke(prompt)\n",
    "    \n",
    "    return {\"language_feedback\": result.feedback, \"individual_scores\": [result.score]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1e028e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_analysis(state: UPSCState):\n",
    "    \n",
    "    prompt = f\"Evaluate the analytical depth of the following essay. Provide a score between 1 and 10 and detailed feedback.\\n\\nEssay:\\n{state['essay']}\"\n",
    "    result = structured_model.invoke(prompt)\n",
    "    \n",
    "    return {\"analysis_feedback\": result.feedback, \"individual_scores\": [result.score]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dda02657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clarity(state: UPSCState):\n",
    "    \n",
    "    prompt = f\"Evaluate the clarity and coherence of the following essay. Provide a score between 1 and 10 and detailed feedback.\\n\\nEssay:\\n{state['essay']}\"\n",
    "    result = structured_model.invoke(prompt)\n",
    "    \n",
    "    return {\"clarity_feedback\": result.feedback, \"individual_scores\": [result.score]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c74adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_evaluation(state: UPSCState):\n",
    "\n",
    "    # summary feedback\n",
    "    prompt = f\"Based on the following feedbacks:\\nLanguage Feedback: {state['language_feedback']}\\nAnalysis Feedback: {state['analysis_feedback']}\\nClarity Feedback: {state['clarity_feedback']}\\nProvide an overall evaluation summary for the essay.\"\n",
    "    overall_feedback = model.invoke(prompt).content\n",
    "\n",
    "    # calculating average score\n",
    "    total_score = sum(state['individual_scores'])\n",
    "    average_score = total_score / len(state['individual_scores'])\n",
    "    \n",
    "    return {\"overall_feedback\": overall_feedback, \"average_score\": average_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0857452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining graph\n",
    "graph = StateGraph(UPSCState)\n",
    "\n",
    "# adding nodes\n",
    "graph.add_node(\"evaluate_language\", evaluate_language)\n",
    "graph.add_node(\"evaluate_analysis\", evaluate_analysis)\n",
    "graph.add_node(\"evaluate_clarity\", evaluate_clarity)\n",
    "graph.add_node(\"final_evaluation\", final_evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
